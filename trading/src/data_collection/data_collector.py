"""
TimescaleDBì—ì„œ ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“ˆ
"""
import os
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Union, Any
import logging
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import sys
import os
import argparse
from collections import Counter

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.append(project_root)
from src.config.config import (
    DB_USER,
    DB_PASSWORD,
    DB_HOST,
    DB_PORT,
    DB_NAME,
    TARGET_SYMBOLS,
    DATA_DIR,
    LOGGER,
    # í•˜í˜„ ì¶”ê°€ ì½”ë“œ ì•„ë˜ ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ ì¶”ê°€
    DATA_START_DATE,
    DATA_END_DATE
)
from src.utils.utils import create_directory, save_to_csv, load_from_csv

class DataCollector:
    """
    TimescaleDBì—ì„œ ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(
        self,
        user: str = DB_USER,
        password: str = DB_PASSWORD,
        host: str = DB_HOST,
        port: Union[str, int] = DB_PORT,
        db_name: str = DB_NAME,
        symbols: List[str] = None,
        # í•˜í˜„ ì¶”ê°€ ì½”ë“œ ì•„ë˜ ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ ì¶”ê°€
        start_date: str = DATA_START_DATE,
        end_date: str = DATA_END_DATE
    ):
        """
        DataCollector í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            user: ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ìëª…
            password: ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸
            host: ë°ì´í„°ë² ì´ìŠ¤ í˜¸ìŠ¤íŠ¸
            port: ë°ì´í„°ë² ì´ìŠ¤ í¬íŠ¸
            db_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
            symbols: ìˆ˜ì§‘í•  ì£¼ì‹ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (Noneì¸ ê²½ìš° ì„¤ì • íŒŒì¼ì˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.user = user
        self.password = password
        self.host = host
        self.port = port
        self.db_name = db_name
        self.symbols = symbols if symbols is not None else TARGET_SYMBOLS
        self.engine = None
        self.data_dir = DATA_DIR
        # í•˜í˜„ ì¶”ê°€ ì½”ë“œ ì•„ë˜ ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ ì¶”ê°€
        self.start_date = start_date
        self.end_date = end_date    
        create_directory(self.data_dir)
        self._create_engine()
        LOGGER.info(f"DataCollector ì´ˆê¸°í™” ì™„ë£Œ: {len(self.symbols)}ê°œ ì¢…ëª© ëŒ€ìƒ")
        LOGGER.info(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {self.start_date} ~ {self.end_date}")

    def _create_engine(self) -> None:
        """
        SQLAlchemy ì—”ì§„ ìƒì„±
        """
        try:
            self.engine = create_engine(
                f"postgresql+psycopg2://{self.user}:{self.password}@{self.host}:{self.port}/{self.db_name}"
            )
            LOGGER.info("DB ì—”ì§„ ìƒì„± ì„±ê³µ")
        except SQLAlchemyError as e:
            LOGGER.error(f"DB ì—”ì§„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
   
    def load_data(self, symbol: str) -> pd.DataFrame:
        
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŠ¹ì • ì‹¬ë³¼ì˜ ì£¼ì‹ ë°ì´í„° ë¡œë“œ
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            
        Returns:
            ë¡œë“œëœ ì£¼ì‹ ë°ì´í„° ë°ì´í„°í”„ë ˆì„
        """
                
        # ê¸°ì¡´ ì¿¼ë¦¬ 
        query = f"""
            SELECT *
            FROM ticker_{symbol.lower()}
            WHERE timestamp >= '{self.start_date}' 
            AND timestamp <= '{self.end_date}'
            ORDER BY timestamp ASC;
        """
        print(f'query :{query}')
        try:
            LOGGER.info(f"{symbol} ë°ì´í„° ë¡œë“œ ì‹œì‘...")
            df = pd.read_sql(query, self.engine)
            
            if 'timestamp' not in df.columns:
                LOGGER.warning(f"{symbol} í…Œì´ë¸”ì— 'timestamp' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            
            # ì»¬ëŸ¼ ì œê±°
            df.drop(columns=['transactions', 'vwap'], inplace=True, errors='ignore')
            
            LOGGER.info(f"{symbol} ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
            return df
            
        except SQLAlchemyError as e:
            LOGGER.error(f"{symbol} ë°ì´í„° ë¡œë“œ ì¤‘ DB ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
        except Exception as e:
            LOGGER.error(f"{symbol} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
    
    def load_all_data(self) -> Dict[str, pd.DataFrame]:
        """
        ëª¨ë“  ì‹¬ë³¼ì— ëŒ€í•œ ë°ì´í„° ë¡œë“œ

        Returns:
            ì‹¬ë³¼ì„ í‚¤ë¡œ í•˜ê³  ë°ì´í„°í”„ë ˆì„ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        """
        all_data = {}

        for symbol in self.symbols:
            try:
                # âœ… ì¤‘ë³µ ì²´í¬ ë¨¼ì € ì‹¤í–‰
                dup_count = self.check_duplicate_timestamps(symbol)
                if dup_count > 0:
                    LOGGER.warning(f"[ì¤‘ë³µ ê²½ê³ ] {symbol} í…Œì´ë¸”ì— ì¤‘ë³µëœ timestampê°€ {dup_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.")

                data = self.load_data(symbol)
                if not data.empty:
                    all_data[symbol] = data
            except Exception as e:
                LOGGER.error(f"{symbol} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        LOGGER.info(f"ì´ {len(all_data)}/{len(self.symbols)} ì¢…ëª© ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return all_data
    
    def save_data(self, data: Dict[str, pd.DataFrame], subdir: str = None) -> None:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            data: ì‹¬ë³¼ì„ í‚¤ë¡œ í•˜ê³  ë°ì´í„°í”„ë ˆì„ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            subdir: ì €ì¥í•  í•˜ìœ„ ë””ë ‰í† ë¦¬ (Noneì¸ ê²½ìš° ë‚ ì§œ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±)
        """
        if subdir is None:
            subdir = datetime.now().strftime("%Y%m%d")
        
        save_dir = self.data_dir / subdir
        create_directory(save_dir)
        
        for symbol, df in data.items():
            file_path = save_dir / f"{symbol}.csv"
            save_to_csv(df, file_path)
        
        LOGGER.info(f"ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ: {save_dir}")
    
    def check_tables(self) -> List[str]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” í™•ì¸
        
        Returns:
            í…Œì´ë¸” ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        try:
            query = """
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name ~ '(aapl|msft|googl|goog|amzn|nvda|meta|tsla)';
            """
            with self.engine.connect() as conn:
                result = conn.execute(text(query))
                tables = [row[0] for row in result]
            
            LOGGER.info(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” í™•ì¸ë¨")
            return tables
        
        except SQLAlchemyError as e:
            LOGGER.error(f"í…Œì´ë¸” í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def get_data_range(self, symbol: str) -> Dict[str, datetime]:
        """
        íŠ¹ì • ì‹¬ë³¼ì˜ ë°ì´í„° ê¸°ê°„ ì¡°íšŒ
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            
        Returns:
            ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì´ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
        """
        query = f"""
            SELECT 
                MIN(timestamp) as start_date,
                MAX(timestamp) as end_date
            FROM ticker_{symbol.lower()};
        """
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(query))
                row = result.fetchone()
                
            if row and row[0] and row[1]:
                range_info = {
                    'start_date': row[0],
                    'end_date': row[1],
                    'days': (row[1] - row[0]).days
                }
                LOGGER.info(f"{symbol} ë°ì´í„° ê¸°ê°„: {range_info['start_date']} ~ {range_info['end_date']} ({range_info['days']}ì¼)")
                return range_info
            else:
                LOGGER.warning(f"{symbol} í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë‚ ì§œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {'start_date': None, 'end_date': None, 'days': 0}
                
        except SQLAlchemyError as e:
            LOGGER.error(f"{symbol} ë°ì´í„° ê¸°ê°„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {'start_date': None, 'end_date': None, 'days': 0}
    
    def load_and_save(self) -> Dict[str, pd.DataFrame]:
        """
        ë°ì´í„° ë¡œë“œ ë° ì €ì¥ì„ í•œ ë²ˆì— ìˆ˜í–‰
        
        Returns:
            ë¡œë“œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        data = self.load_all_data()
        if data:
            self.save_data(data)
        return data


    def check_duplicate_timestamps(self, symbol: str) -> int:
        """
        íŠ¹ì • ì‹¬ë³¼ í…Œì´ë¸”ì—ì„œ timestamp ì¤‘ë³µ ê°œìˆ˜ í™•ì¸

        Returns:
            ì¤‘ë³µ timestamp ê°œìˆ˜
        """
        query = f"""
            SELECT COUNT(*) - COUNT(DISTINCT timestamp) AS duplicate_count
            FROM ticker_{symbol.lower()};
        """
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(query))
                duplicate_count = result.scalar()
            LOGGER.info(f"{symbol} ì¤‘ë³µ timestamp ê°œìˆ˜: {duplicate_count}")
            return duplicate_count
        except SQLAlchemyError as e:
            LOGGER.error(f"{symbol} ì¤‘ë³µ timestamp ì²´í¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return -1

if __name__ == "__main__":
    from src.config.config import config
    
    parser = argparse.ArgumentParser(description="ì‹¬ë³¼ë³„ ë°ì´í„° ìˆ˜ì§‘")
    parser.add_argument("--symbols", nargs="+", help="ìˆ˜ì§‘í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸", default=config.trading_symbols)
    args = parser.parse_args()
    
    # DataCollectorì— ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
    collector = DataCollector(
        # user='postgres',
        # password='mysecretpassword',
        # host='192.168.40.193',
        # port=5432,
        # db_name='mydb',
        symbols=args.symbols  # ì—¬ê¸°ê°€ í•µì‹¬!
    )
    
    print(f"ìˆ˜ì§‘ ëŒ€ìƒ ì‹¬ë³¼: {collector.symbols}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸
    tables = collector.check_tables()
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”: {tables}")
    
    # ë°ì´í„° ë¡œë“œ ë° ì €ì¥
    data = collector.load_and_save()
    print(f"ë¡œë“œëœ ë°ì´í„° ì¢…ëª©: {list(data.keys())}")
    
    #í•˜í˜„ ì¤‘ë³µì½”ë“œ í™•ì¸

    from collections import Counter
    print('--------------------------------------------------------------------------------------------------------')
    for symbol, df in data.items():
        print(f"\n[ì—°ì†ëœ ì¢…ê°€ ì¤‘ë³µ ì²´í¬ (30íšŒ ì´ìƒ): {symbol}]")

        df = df.reset_index(drop=True)  # ì¸ë±ìŠ¤ë¥¼ ìˆ«ìë¡œ ì´ˆê¸°í™”
        close_series = df['close']

        start_idx = None
        current_value = None
        count = 0

        for i in range(len(close_series)):
            if i == 0:
                current_value = close_series[i]
                start_idx = i
                count = 1
                continue

            if close_series[i] == current_value:
                count += 1
            else:
                if count >= 30:
                    end_idx = i - 1
                    print(f"ì—°ì†ëœ 'close' ê°’ {current_value}ì´ {count}ë²ˆ ë°˜ë³µë¨ â†’ ì‹œì‘ ì¸ë±ìŠ¤: {start_idx}, ì¢…ë£Œ ì¸ë±ìŠ¤: {end_idx}")
                # reset
                current_value = close_series[i]
                start_idx = i
                count = 1

        # ë§ˆì§€ë§‰ êµ¬ê°„ë„ ê²€ì‚¬
        if count >= 30:
            end_idx = len(close_series) - 1
            print(f"ì—°ì†ëœ 'close' ê°’ {current_value}ì´ {count}ë²ˆ ë°˜ë³µë¨ â†’ ì‹œì‘ ì¸ë±ìŠ¤: {start_idx}, ì¢…ë£Œ ì¸ë±ìŠ¤: {end_idx}")

        print("í™•ì¸ ì™„ë£Œ.")
    print('--------------------------------------------------------------------------------------------------------')



    
    # ì²« ë²ˆì§¸ ì¢…ëª©ì˜ ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
    if data:
        symbol = list(data.keys())[0]
        print(f"\n{symbol} ë°ì´í„° ìƒ˜í”Œ:")
        print(data[symbol].head())