"""
ìˆœì°¨ì  ì—í”¼ì†Œë“œ ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤ (ìˆ˜ì •ëœ ë²„ì „)
ì „ì²´ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
"""
import numpy as np
from typing import Tuple, Dict, Any
import logging

from src.config.ea_teb_config import (
    WINDOW_SIZE,
    MAX_STEPS_PER_EPISODE,
    overlap_ratio
)


class SequentialEpisodeManager:
    """
    ìˆœì°¨ì  ì—í”¼ì†Œë“œ ë°ì´í„° ê´€ë¦¬ì
    - ì „ì²´ ë°ì´í„°ë¥¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ìˆœì°¨ì ìœ¼ë¡œ ë¶„í• 
    - ì—í”¼ì†Œë“œë³„ë¡œ ë‹¤ë¥¸ ì‹œê°„ êµ¬ê°„ í•™ìŠµ
    - 100% ë°ì´í„° í™œìš©ë¥  ë‹¬ì„±
    """
    
    def __init__(
        self,
        data_length: int, 
        window_size: int = WINDOW_SIZE, 
        max_steps: int = MAX_STEPS_PER_EPISODE,
        min_steps: int = 100,  # ìµœì†Œ ì—í”¼ì†Œë“œ ê¸¸ì´
        overlap_ratio: float = overlap_ratio,  # ì—í”¼ì†Œë“œ ê°„ ê²¹ì¹¨ ë¹„ìœ¨ (0.0 = ê²¹ì¹¨ ì—†ìŒ, 0.1 = 10% ê²¹ì¹¨)
        adaptive_length: bool = True,  # ì ì‘í˜• ê¸¸ì´ ì‚¬ìš©
        logger: logging.Logger = None
    ):
        """
        ìˆœì°¨ì  ì—í”¼ì†Œë“œ ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            data_length: ì „ì²´ ë°ì´í„° ê¸¸ì´
            window_size: ê´€ì¸¡ ìœˆë„ìš° í¬ê¸°
            max_steps: ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í… ìˆ˜
            min_steps: ìµœì†Œ ì—í”¼ì†Œë“œ ê¸¸ì´
            overlap_ratio: ì—í”¼ì†Œë“œ ê°„ ê²¹ì¹¨ ë¹„ìœ¨ (0.0~0.5 ê¶Œì¥)
            adaptive_length: ì ì‘í˜• ê¸¸ì´ ì‚¬ìš© ì—¬ë¶€
            logger: ë¡œê¹…ìš© ë¡œê±°
        """
        self.data_length = data_length
        self.window_size = WINDOW_SIZE
        self.max_steps = max_steps
        self.min_steps = min_steps
        self.overlap_ratio = max(0.0, min(overlap_ratio, 0.5))
        self.adaptive_length = adaptive_length
        self.logger = logger or logging.getLogger(__name__)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤ì œ ë°ì´í„° ê¸¸ì´
        self.usable_length = data_length - window_size
        
        # ì—í”¼ì†Œë“œ ê³„íš ìƒì„±
        self.episode_plan = self._create_adaptive_episode_plan()
        
        # í˜„ì¬ ìƒíƒœ ì¶”ì 
        self.current_cycle = 0
        self.current_episode_in_cycle = 0
        
        self._log_initialization()
    
    def _create_adaptive_episode_plan(self) -> list:
        """ì ì‘í˜• ì—í”¼ì†Œë“œ ê³„íš ìƒì„±"""
        plan = []
        current_pos = 0
        episode_id = 0
        
        while current_pos < self.usable_length:
            # ë‚¨ì€ ë°ì´í„° ê¸¸ì´ ê³„ì‚°
            remaining_data = self.usable_length - current_pos
            
            if self.adaptive_length:
                # ì ì‘í˜• ê¸¸ì´ ê³„ì‚°
                if remaining_data <= self.max_steps:
                    # ë‚¨ì€ ë°ì´í„°ê°€ max_steps ì´í•˜ë©´ ëª¨ë‘ ì‚¬ìš©
                    episode_length = remaining_data
                elif remaining_data <= self.max_steps * 1.5:
                    # 1.5ë°° ì´í•˜ë©´ ì ˆë°˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë‘ ì—í”¼ì†Œë“œë¡œ
                    episode_length = remaining_data // 2
                else:
                    # ì¶©ë¶„íˆ í¬ë©´ max_steps ì‚¬ìš©
                    episode_length = self.max_steps
            else:
                # ê³ ì • ê¸¸ì´ ì‚¬ìš©
                episode_length = min(self.max_steps, remaining_data)
            
            # ìµœì†Œ ê¸¸ì´ ë³´ì¥
            if episode_length < self.min_steps and remaining_data > self.min_steps:
                episode_length = self.min_steps
            
            # ì—í”¼ì†Œë“œ ì •ë³´ ìƒì„±
            end_pos = min(current_pos + episode_length, self.usable_length)
            actual_length = end_pos - current_pos
            
            if actual_length >= self.min_steps:  # ìµœì†Œ ê¸¸ì´ ì´ìƒì¸ ê²½ìš°ë§Œ ì¶”ê°€
                episode_info = {
                    'episode_id': episode_id,
                    'start_index': current_pos,
                    'end_index': end_pos,
                    'planned_length': actual_length,
                    'actual_length': actual_length,  # í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                    'coverage_start_pct': (current_pos / self.usable_length) * 100,
                    'coverage_end_pct': (end_pos / self.usable_length) * 100,
                    'cycle_number': 0,  # ê¸°ë³¸ê°’
                    'episode_in_cycle': episode_id,
                    'episode_type': self._classify_episode_type({'planned_length': actual_length}),
                    'is_last_in_cycle': False  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                }
                plan.append(episode_info)
                episode_id += 1
            
            # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì‹œì‘ì  ê³„ì‚° (ê²¹ì¹¨ ê³ ë ¤)
            if self.overlap_ratio > 0:
                step_size = int(actual_length * (1 - self.overlap_ratio))
                current_pos += max(step_size, self.min_steps)
            else:
                current_pos = end_pos
            
            # ë¬´í•œë£¨í”„ ë°©ì§€
            if current_pos >= self.usable_length or actual_length == 0:
                break
        
        # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œ í‘œì‹œ
        if plan:
            plan[-1]['is_last_in_cycle'] = True
        
        return plan
    
    def _classify_episode_type(self, episode_plan: Dict) -> str:
        """ì—í”¼ì†Œë“œ íƒ€ì… ë¶„ë¥˜"""
        length = episode_plan['planned_length']
        
        if length >= self.max_steps * 0.9:
            return "full"  # ê±°ì˜ ìµœëŒ€ ê¸¸ì´
        elif length <= self.min_steps * 1.1:
            return "minimal"  # ìµœì†Œ ê¸¸ì´
        elif length >= self.max_steps * 0.5:
            return "standard"  # í‘œì¤€ ê¸¸ì´
        else:
            return "short"  # ì§§ì€ ê¸¸ì´
    
    def get_episode_info(self, episode_num: int) -> Tuple[int, Dict[str, Any]]:
        """
        ì—í”¼ì†Œë“œ ì •ë³´ ë°˜í™˜
        
        Args:
            episode_num: ì—í”¼ì†Œë“œ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)
            
        Returns:
            (ì‹œì‘_ì¸ë±ìŠ¤, ë©”íƒ€ì •ë³´) íŠœí”Œ
        """
        if not self.episode_plan:
            # ë¹ˆ ê³„íšì¸ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            return 0, {
                'start_index': 0,
                'end_index': min(self.max_steps, self.usable_length),
                'actual_length': min(self.max_steps, self.usable_length),
                'cycle_number': 0,
                'episode_in_cycle': 0,
                'episode_type': 'default',
                'is_last_in_cycle': True,
                'coverage_start_pct': 0.0,
                'coverage_end_pct': 100.0
            }
        
        # ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¥¼ ê³„íš ë²”ìœ„ ë‚´ë¡œ ì¡°ì •
        episode_index = episode_num % len(self.episode_plan)
        episode_info = self.episode_plan[episode_index].copy()
        
        # ì‚¬ì´í´ ì •ë³´ ì—…ë°ì´íŠ¸
        cycle_num = episode_num // len(self.episode_plan)
        episode_info['cycle_number'] = cycle_num
        
        return episode_info['start_index'], episode_info
    
    def get_coverage_summary(self) -> Dict[str, Any]:
        """ì „ì²´ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ìš”ì•½ ì •ë³´"""
        if not self.episode_plan:
            return {}
        
        total_planned_steps = sum(ep['planned_length'] for ep in self.episode_plan)
        
        # ê²¹ì¹¨ ê³„ì‚°
        total_overlap = 0
        for i in range(len(self.episode_plan) - 1):
            curr_end = self.episode_plan[i]['end_index']
            next_start = self.episode_plan[i + 1]['start_index']
            if curr_end > next_start:
                total_overlap += curr_end - next_start
        
        unique_covered = total_planned_steps - total_overlap
        
        # ì—í”¼ì†Œë“œ íƒ€ì…ë³„ í†µê³„
        episode_types = {}
        for ep in self.episode_plan:
            ep_type = ep.get('episode_type', self._classify_episode_type(ep))
            episode_types[ep_type] = episode_types.get(ep_type, 0) + 1
        
        return {
            'total_data_length': self.data_length,
            'usable_length': self.usable_length,
            'total_episodes': len(self.episode_plan),
            'total_planned_steps': total_planned_steps,
            'unique_covered_steps': unique_covered,
            'total_overlap_steps': total_overlap,
            'unique_coverage_pct': (unique_covered / self.usable_length) * 100,
            'total_coverage_pct': (total_planned_steps / self.usable_length) * 100,
            'average_episode_length': total_planned_steps / len(self.episode_plan),
            'episode_types': episode_types,
            'adaptive_length_enabled': self.adaptive_length,
            'min_episode_length': min(ep['planned_length'] for ep in self.episode_plan),
            'max_episode_length': max(ep['planned_length'] for ep in self.episode_plan)
        }
    
    def _log_initialization(self):
        """ì´ˆê¸°í™” ì •ë³´ ë¡œê¹…"""
        summary = self.get_coverage_summary()
        
        self.logger.info("=" * 70)
        self.logger.info("ğŸ”„ ì ì‘í˜• ìˆœì°¨ì  ì—í”¼ì†Œë“œ ê´€ë¦¬ì ì´ˆê¸°í™”")
        self.logger.info("=" * 70)
        self.logger.info(f"ğŸ“Š ì „ì²´ ë°ì´í„° ê¸¸ì´: {self.data_length:,}")
        self.logger.info(f"ğŸ¯ ì‚¬ìš© ê°€ëŠ¥ ê¸¸ì´: {self.usable_length:,}")
        self.logger.info(f"ğŸ“ˆ ì´ ì—í”¼ì†Œë“œ ìˆ˜: {summary['total_episodes']}")
        self.logger.info(f"ğŸ”§ ì ì‘í˜• ê¸¸ì´: {'í™œì„±í™”' if self.adaptive_length else 'ë¹„í™œì„±í™”'}")
        self.logger.info(f"ğŸ“ ì—í”¼ì†Œë“œ ê¸¸ì´ ë²”ìœ„: {summary['min_episode_length']}~{summary['max_episode_length']}")
        self.logger.info(f"ğŸ“ í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´: {summary['average_episode_length']:.1f}")
        self.logger.info(f"ğŸ”— ê²¹ì¹¨ ë¹„ìœ¨: {self.overlap_ratio:.1%}")
        self.logger.info(f"ğŸ¯ ê³ ìœ  ì»¤ë²„ë¦¬ì§€: {summary['unique_coverage_pct']:.1f}%")
        
        # ì—í”¼ì†Œë“œ íƒ€ì… ë¶„í¬
        if summary['episode_types']:
            self.logger.info(f"ğŸ“Š ì—í”¼ì†Œë“œ íƒ€ì… ë¶„í¬:")
            for ep_type, count in summary['episode_types'].items():
                self.logger.info(f"   â””â”€ {ep_type}: {count}ê°œ")
        
        self.logger.info("=" * 70)
        
        # ì²˜ìŒ ëª‡ ê°œ ì—í”¼ì†Œë“œ ê³„íš ë¯¸ë¦¬ë³´ê¸°
        self.logger.info("ğŸ“‹ ì—í”¼ì†Œë“œ ê³„íš ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):")
        for i in range(min(5, len(self.episode_plan))):
            ep = self.episode_plan[i]
            ep_type = ep.get('episode_type', 'unknown')
            self.logger.info(
                f"   Episode {i:2d}: [{ep['start_index']:5d}~{ep['end_index']:5d}] "
                f"({ep['planned_length']:3d} steps, {ep_type})"
            )
        
        if len(self.episode_plan) > 5:
            self.logger.info(f"   ... ì´ {len(self.episode_plan)}ê°œ ì—í”¼ì†Œë“œ")
        self.logger.info("=" * 70)


class SequentialTradingEnvironment:
    """
    ìˆœì°¨ì  ë°ì´í„° í™œìš©ì„ ìœ„í•œ TradingEnvironment í™•ì¥ (ìˆ˜ì •ë¨)
    """
    
    def __init__(self, base_env, episode_manager: SequentialEpisodeManager):
        """
        ê°œì„ ëœ ìˆœì°¨ì  ê±°ë˜ í™˜ê²½ ì´ˆê¸°í™”
        
        Args:
            base_env: ê¸°ì¡´ TradingEnvironment ì¸ìŠ¤í„´ìŠ¤
            episode_manager: ìˆœì°¨ì  ì—í”¼ì†Œë“œ ê´€ë¦¬ì
        """
        self.base_env = base_env
        self.episode_manager = episode_manager
        self.episode_meta_info = {}
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê±°
        self.logger = getattr(base_env, 'logger', None) or logging.getLogger(__name__)
        
    def reset(self, episode_num: int = None):
        """
        í™˜ê²½ ì¬ì„¤ì • (ê°œì„ ëœ ìˆœì°¨ì  ì‹œì‘ì )
        
        Args:
            episode_num: ì—í”¼ì†Œë“œ ë²ˆí˜¸ (í•„ìˆ˜)
        """
        if episode_num is None:
            self.logger.warning("âš ï¸ episode_numì´ Noneì…ë‹ˆë‹¤. 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            episode_num = 0
        
        # ë””ë²„ê¹… ë¡œê·¸
        self.logger.debug(f"ğŸ”„ Episode {episode_num} reset ì‹œì‘")
        
        # ì ì‘í˜• ì‹œì‘ì  ê°€ì ¸ì˜¤ê¸°
        start_index, self.episode_meta_info = self.episode_manager.get_episode_info(episode_num)
        
        # ë””ë²„ê¹… ë¡œê·¸
        self.logger.debug(f"ğŸ“Š Episode {episode_num}: ì‹œì‘ì  {start_index}, ë²”ìœ„ [{self.episode_meta_info['start_index']}~{self.episode_meta_info['end_index']}]")
        
        # ê¸°ë³¸ í™˜ê²½ ì´ˆê¸°í™” (ì‹œì‘ì  ì„¤ì •)
        self.base_env.current_step = start_index
        self.base_env.balance = self.base_env.initial_balance
        self.base_env.shares_held = 0
        self.base_env.cost_basis = 0
        self.base_env.total_shares_purchased = 0
        self.base_env.total_shares_sold = 0
        self.base_env.total_sales_value = 0
        self.base_env.total_commission = 0
        self.base_env.trade_executed = False
        self.base_env.position = "í™€ë“œ"
        self.base_env.previous_shares_held = 0
        self.base_env.invalid_sell_penalty = False
        
        # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        self.base_env.states_history = []
        self.base_env.actions_history = []
        self.base_env.rewards_history = []
        self.base_env.portfolio_values_history = []
        
        # ë¶„ì„ìš© íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        if hasattr(self.base_env, 'trade_effects_history'):
            self.base_env.trade_effects_history = []
            self.base_env.market_effects_history = []
            self.base_env.combined_effects_history = []
        
        return self.base_env._get_observation()
    
    def step(self, action):
        """
        í™˜ê²½ì—ì„œ í•œ ìŠ¤í… ì§„í–‰ (ê°œì„ ëœ ì¢…ë£Œ ì¡°ê±´)
        """
        # ê¸°ë³¸ ìŠ¤í… ì‹¤í–‰
        obs, reward, done, info = self.base_env.step(action)
        
        # ê°œì„ ëœ ì¢…ë£Œ ì¡°ê±´ ì²´í¬
        current_step = self.base_env.current_step
        start_index = self.episode_meta_info['start_index']
        end_index = self.episode_meta_info['end_index']
        planned_length = self.episode_meta_info['actual_length']
        
        steps_in_episode = current_step - start_index
        
        # ë‹¤ì¤‘ ì¢…ë£Œ ì¡°ê±´ (ìš°ì„ ìˆœìœ„ëŒ€ë¡œ)
        natural_end = (current_step >= end_index)  # ê³„íšëœ ì¢…ë£Œì  ë„ë‹¬
        planned_end = (steps_in_episode >= planned_length)  # ê³„íšëœ ê¸¸ì´ ë„ë‹¬
        safety_end = (steps_in_episode >= planned_length * 1.2)  # ì•ˆì „ì¥ì¹˜ (20% ì—¬ìœ )
        
        should_end = natural_end or planned_end or done
        
        if should_end and not done:
            done = True
            termination_reasons = []
            if natural_end:
                termination_reasons.append("ìì—° ì¢…ë£Œì  ë„ë‹¬")
            if planned_end:
                termination_reasons.append("ê³„íšëœ ê¸¸ì´ ë‹¬ì„±")
            if safety_end:
                termination_reasons.append("ì•ˆì „ì¥ì¹˜ ì‘ë™")
            
            self.logger.debug(f"âœ… Episode ì¢…ë£Œ: {', '.join(termination_reasons)} (step {current_step}, episode_steps {steps_in_episode})")
        
        # ë©”íƒ€ ì •ë³´ ì—…ë°ì´íŠ¸
        info.update({
            'episode_meta': self.episode_meta_info,
            'sequential_manager': 'improved',
            'data_coverage': f"{self.episode_meta_info['coverage_start_pct']:.1f}%~{self.episode_meta_info['coverage_end_pct']:.1f}%",
            'current_step': current_step,
            'episode_start': start_index,
            'episode_end': end_index,
            'steps_in_episode': steps_in_episode,
            'episode_progress': f"{steps_in_episode}/{planned_length}",
            'episode_type': self.episode_meta_info.get('episode_type', 'unknown')
        })
        
        return obs, reward, done, info
    
    def get_risk_metrics(self) -> Dict[str, float]:
        """ë¦¬ìŠ¤í¬ ì§€í‘œ ë°˜í™˜ (base_envì—ì„œ ê°€ì ¸ì˜´)"""
        if hasattr(self.base_env, 'get_risk_metrics'):
            return self.base_env.get_risk_metrics()
        else:
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'max_drawdown_pct': 0.0,
                'max_daily_loss_pct': 0.0,
                'peak_portfolio_value': getattr(self.base_env, 'initial_balance', 100000.0),
                'daily_start_portfolio': getattr(self.base_env, 'initial_balance', 100000.0)
            }
    
    def _check_risk_limits(self, current_portfolio_value: float) -> Tuple[bool, bool]:
        """ë¦¬ìŠ¤í¬ í•œë„ ì²´í¬ (base_envì— ìœ„ì„)"""
        if hasattr(self.base_env, '_check_risk_limits'):
            return self.base_env._check_risk_limits(current_portfolio_value)
        else:
            return False, False
        
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ base_envì— ìœ„ì„
    def __getattr__(self, name):
        return getattr(self.base_env, name)


def create_sequential_training_setup(base_env, overlap_ratio: float = 0.0, logger=None):
    """
    ìˆœì°¨ì  í•™ìŠµ ì„¤ì • ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        base_env: ê¸°ë³¸ TradingEnvironment
        overlap_ratio: ì—í”¼ì†Œë“œ ê°„ ê²¹ì¹¨ ë¹„ìœ¨
        logger: ë¡œê±°
        
    Returns:
        (SequentialTradingEnvironment, SequentialEpisodeManager)
    """
    if logger is None:
        logger = logging.getLogger(__name__)
    
    # ìˆœì°¨ì  ì—í”¼ì†Œë“œ ê´€ë¦¬ì ìƒì„±
    episode_manager = SequentialEpisodeManager(
        data_length=base_env.data_length,
        window_size=base_env.window_size,
        max_steps=MAX_STEPS_PER_EPISODE,
        min_steps=100,
        overlap_ratio=overlap_ratio,
        adaptive_length=True,
        logger=logger
    )
    
    # ìˆœì°¨ì  í™˜ê²½ ìƒì„±
    sequential_env = SequentialTradingEnvironment(base_env, episode_manager)
    
    return sequential_env, episode_manager


def create_improved_sequential_training_setup(base_env, overlap_ratio: float = 0.1, 
                                            adaptive_length: bool = True, logger=None):
    """
    ê°œì„ ëœ ìˆœì°¨ì  í•™ìŠµ ì„¤ì • ìƒì„± í—¬í¼ í•¨ìˆ˜ (í˜¸í™˜ì„± í•¨ìˆ˜)
    
    Args:
        base_env: ê¸°ë³¸ TradingEnvironment
        overlap_ratio: ì—í”¼ì†Œë“œ ê°„ ê²¹ì¹¨ ë¹„ìœ¨
        adaptive_length: ì ì‘í˜• ê¸¸ì´ ì‚¬ìš© ì—¬ë¶€
        logger: ë¡œê±°
        
    Returns:
        (SequentialTradingEnvironment, SequentialEpisodeManager)
    """
    # ê¸°ë³¸ í•¨ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)
    return create_sequential_training_setup(base_env, overlap_ratio, logger)


# ë””ë²„ê¹…ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_sequential_episodes(sequential_env, num_test_episodes=5):
    """ìˆœì°¨ì  ì—í”¼ì†Œë“œ í…ŒìŠ¤íŠ¸"""
    print("="*60)
    print("ğŸ§ª ìˆœì°¨ì  ì—í”¼ì†Œë“œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    for episode in range(num_test_episodes):
        print(f"\nğŸ“‹ Episode {episode} í…ŒìŠ¤íŠ¸:")
        
        # ë¦¬ì…‹
        obs = sequential_env.reset(episode_num=episode)
        print(f"   ë¦¬ì…‹ ì™„ë£Œ: current_step = {sequential_env.base_env.current_step}")
        
        # ë©”íƒ€ ì •ë³´ í™•ì¸
        meta = sequential_env.episode_meta_info
        print(f"   ë°ì´í„° ë²”ìœ„: [{meta['start_index']}~{meta['end_index']}]")
        print(f"   ì‹¤ì œ ê¸¸ì´: {meta['actual_length']} steps")
        print(f"   ì»¤ë²„ë¦¬ì§€: {meta['coverage_start_pct']:.1f}%~{meta['coverage_end_pct']:.1f}%")
        
        # ëª‡ ìŠ¤í… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
        for step in range(5):
            obs, reward, done, info = sequential_env.step(0.0)  # í™€ë“œ ì•¡ì…˜
            if done:
                print(f"   Episode {episode} - Step {step+1}ì—ì„œ ì¢…ë£Œë¨")
                break
        else:
            print(f"   Episode {episode} - 5 steps ì •ìƒ ì‹¤í–‰")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")