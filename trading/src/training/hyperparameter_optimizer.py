#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SAC í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import time
import json
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.append(project_root)

# ê²½ê³  ì–µì œ
warnings.filterwarnings('ignore')

try:
    import optuna
    from optuna.pruners import MedianPruner
    from optuna.samplers import TPESampler
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("âš ï¸ Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install optunaë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

import torch
import numpy as np
import pandas as pd

from src.config.ea_teb_config import (
    DEVICE,
    TARGET_SYMBOLS,
    LOGGER,
    INITIAL_BALANCE,
    WINDOW_SIZE,
    NUM_EPISODES,
    BATCH_SIZE,
    MAX_STEPS_PER_EPISODE,
    MODEL_DEFAULTS,
    get_model_config
)

from src.data_collection.data_collector import DataCollector
from src.preprocessing.data_processor import DataProcessor
from src.environment.trading_env import create_environment_from_results
from src.models.sac_agent import SACAgent
from src.utils.utils import create_directory, get_timestamp

class HyperparameterOptimizer:
    """
    SAC ëª¨ë¸ì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤
    """
    
    def __init__(
        self,
        symbols: List[str] = None,
        model_type: str = 'mlp',
        n_trials: int = 100,
        n_episodes_per_trial: int = 200,
        optimization_metric: str = 'sharpe_ratio',
        results_dir: str = None,
        use_pruning: bool = True,
        random_seed: int = 42
    ):
        """
        HyperparameterOptimizer ì´ˆê¸°í™”
        
        Args:
            symbols: ìµœì í™”ì— ì‚¬ìš©í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
            model_type: ëª¨ë¸ íƒ€ì… ('mlp', 'cnn', 'lstm', 'mamba')
            n_trials: ìµœì í™” ì‹œë„ íšŸìˆ˜
            n_episodes_per_trial: ê° ì‹œë„ë‹¹ í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
            optimization_metric: ìµœì í™” ì§€í‘œ ('sharpe_ratio', 'total_return', 'final_portfolio_value')
            results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            use_pruning: ì¡°ê¸° ì¢…ë£Œ ì‚¬ìš© ì—¬ë¶€
            random_seed: ëœë¤ ì‹œë“œ
        """
        
        if not OPTUNA_AVAILABLE:
            raise ImportError("Optunaê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install optunaë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        self.symbols = symbols or TARGET_SYMBOLS[:2]  # ê¸°ë³¸ì ìœ¼ë¡œ ì²˜ìŒ 2ê°œ ì‹¬ë³¼ë§Œ ì‚¬ìš©
        self.model_type = model_type.lower()
        self.n_trials = n_trials
        self.n_episodes_per_trial = n_episodes_per_trial
        self.optimization_metric = optimization_metric
        self.use_pruning = use_pruning
        self.random_seed = random_seed
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if results_dir is None:
            timestamp = get_timestamp()
            results_dir = f"hyperopt_results_{self.model_type}_{timestamp}"
        self.results_dir = Path(results_dir)
        create_directory(self.results_dir)
        
        # ë°ì´í„° ì¤€ë¹„
        self.data_results = None
        self.best_trial_info = {}
        
        LOGGER.info(f"ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì´ˆê¸°í™” ì™„ë£Œ")
        LOGGER.info(f"   ëª¨ë¸ íƒ€ì…: {self.model_type.upper()}")
        LOGGER.info(f"   ì‹¬ë³¼: {self.symbols}")
        LOGGER.info(f"   ì‹œë„ íšŸìˆ˜: {self.n_trials}")
        LOGGER.info(f"   ì—í”¼ì†Œë“œ/ì‹œë„: {self.n_episodes_per_trial}")
        LOGGER.info(f"   ìµœì í™” ì§€í‘œ: {self.optimization_metric}")
        
    def prepare_data(self):
        """ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬"""
        LOGGER.info("ğŸ“Š ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ë°ì´í„° ìˆ˜ì§‘
        collector = DataCollector(symbols=self.symbols)
        raw_data = collector.load_all_data()
        
        if not raw_data:
            raise ValueError("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        processor = DataProcessor()
        self.data_results = processor.process_all_symbols(raw_data)
        
        LOGGER.info(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(self.data_results)}ê°œ ì‹¬ë³¼")
        
    def define_hyperparameter_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """
        ëª¨ë¸ íƒ€ì…ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ ì •ì˜
        
        Args:
            trial: Optuna trial ê°ì²´
            
        Returns:
            í•˜ì´í¼íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        """
        # ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        params = {
            # í•™ìŠµë¥  (ë¡œê·¸ ìŠ¤ì¼€ì¼)
            'actor_lr': trial.suggest_float('actor_lr', 1e-5, 1e-2, log=True),
            'critic_lr': trial.suggest_float('critic_lr', 1e-5, 1e-2, log=True),
            'alpha_lr': trial.suggest_float('alpha_lr', 1e-5, 1e-2, log=True),
            
            # SAC íŒŒë¼ë¯¸í„°
            'gamma': trial.suggest_float('gamma', 0.85, 0.999),
            'tau': trial.suggest_float('tau', 0.001, 0.05),
            'alpha_init': trial.suggest_float('alpha_init', 0.05, 0.5),
            
            # ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
            'hidden_dim': trial.suggest_categorical('hidden_dim', [128, 256, 512, 1024]),
            'dropout_rate': trial.suggest_float('dropout_rate', 0.0, 0.5),
            
            # í•™ìŠµ íŒŒë¼ë¯¸í„°
            'batch_size': trial.suggest_categorical('batch_size', [128, 256, 512, 1024]),
            'gradient_clip_norm': trial.suggest_float('gradient_clip_norm', 0.5, 5.0),
            
            # ë²„í¼ íŒŒë¼ë¯¸í„°
            'buffer_capacity': trial.suggest_categorical('buffer_capacity', [50000, 100000, 500000, 1000000]),
        }
        
        # ëª¨ë¸ë³„ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°
        if self.model_type == 'cnn':
            params.update({
                'cnn_dropout_rate': trial.suggest_float('cnn_dropout_rate', 0.1, 0.4),
                # CNNì€ ì´ë¯¸ êµ¬ì¡°ê°€ ì •ì˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë“œë¡­ì•„ì›ƒë§Œ ì¡°ì •
            })
            
        elif self.model_type == 'lstm':
            params.update({
                'lstm_hidden_dim': trial.suggest_categorical('lstm_hidden_dim', [64, 128, 256, 512]),
                'num_lstm_layers': trial.suggest_int('num_lstm_layers', 1, 4),
                'lstm_dropout': trial.suggest_float('lstm_dropout', 0.0, 0.5),
            })
            
        elif self.model_type == 'mlp':
            # MLPëŠ” ìƒíƒœ ì°¨ì›ì´ ê³ ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì—†ìŒ
            pass
        
        return params
    
    def objective(self, trial: optuna.Trial) -> float:
        """
        ìµœì í™” ëª©ì  í•¨ìˆ˜
        
        Args:
            trial: Optuna trial ê°ì²´
            
        Returns:
            ìµœì í™”í•  ìŠ¤ì½”ì–´ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        """
        try:
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
            params = self.define_hyperparameter_space(trial)
            
            # ì‹¬ë³¼ë³„ ì„±ëŠ¥ í‰ê°€
            symbol_scores = []
            
            for symbol in self.symbols:
                if symbol not in self.data_results:
                    continue
                
                try:
                    # í™˜ê²½ ìƒì„±
                    env = create_environment_from_results(
                        results=self.data_results,
                        symbol=symbol,
                        data_type='train',
                        log_level='minimal'  # ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ë¡œê¹… ìµœì†Œí™”
                    )
                    
                    # ëª¨ë¸ ìƒì„±
                    agent = self._create_agent(env, params)
                    
                    # í•™ìŠµ ë° í‰ê°€
                    score = self._train_and_evaluate(agent, env, trial, symbol)
                    
                    if score is not None:
                        symbol_scores.append(score)
                        LOGGER.info(f"   {symbol}: {score:.4f}")
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    del agent, env
                    torch.cuda.empty_cache() if torch.cuda.is_available() else None
                    
                except Exception as e:
                    LOGGER.warning(f"   {symbol} í‰ê°€ ì‹¤íŒ¨: {e}")
                    import traceback
                    LOGGER.debug(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    continue
            
            if not symbol_scores:
                raise optuna.TrialPruned("ëª¨ë“  ì‹¬ë³¼ì—ì„œ í‰ê°€ ì‹¤íŒ¨")
            
            # í‰ê·  ìŠ¤ì½”ì–´ ë°˜í™˜
            final_score = np.mean(symbol_scores)
            
            # ìµœê³  ì„±ëŠ¥ ì¶”ì 
            if trial.number == 0 or final_score > self.best_trial_info.get('score', -np.inf):
                self.best_trial_info = {
                    'trial_number': trial.number,
                    'score': final_score,
                    'params': params,
                    'symbol_scores': dict(zip(self.symbols[:len(symbol_scores)], symbol_scores))
                }
                
                # ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„° ì €ì¥
                self._save_best_params(params, final_score, trial.number)
            
            LOGGER.info(f"Trial {trial.number}: í‰ê·  ìŠ¤ì½”ì–´ = {final_score:.4f}")
            return final_score
            
        except optuna.TrialPruned:
            raise
        except Exception as e:
            LOGGER.error(f"Trial {trial.number} ì‹¤íŒ¨: {e}")
            raise optuna.TrialPruned(f"Trial ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _create_agent(self, env, params: Dict[str, Any]) -> SACAgent:
        """í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì—ì´ì „íŠ¸ ìƒì„±"""
        
        # ì…ë ¥ í˜•íƒœ ê²°ì •
        if self.model_type in ['cnn', 'lstm']:
            input_shape = (WINDOW_SIZE, env.feature_dim)
            state_dim = None
        else:  # mlp
            input_shape = None
            state_dim = WINDOW_SIZE * env.feature_dim + 2
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        agent = SACAgent(
            state_dim=state_dim,
            action_dim=1,
            hidden_dim=params['hidden_dim'],
            actor_lr=params['actor_lr'],
            critic_lr=params['critic_lr'],
            alpha_lr=params['alpha_lr'],
            gamma=params['gamma'],
            tau=params['tau'],
            alpha_init=params['alpha_init'],
            use_cnn=(self.model_type == 'cnn'),
            use_lstm=(self.model_type == 'lstm'),
            input_shape=input_shape,
            model_type=self.model_type,
            dropout_rate=params['dropout_rate'],
            gradient_clip_norm=params['gradient_clip_norm'],
            buffer_capacity=params['buffer_capacity'],
            # LSTM ì „ìš© íŒŒë¼ë¯¸í„°
            lstm_hidden_dim=params.get('lstm_hidden_dim', 128),
            num_lstm_layers=params.get('num_lstm_layers', 2),
            lstm_dropout=params.get('lstm_dropout', 0.2),
            device=DEVICE
        )
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ë°›ì€ ë°°ì¹˜ í¬ê¸° ì ìš©
        agent.batch_size = params['batch_size']
        
        return agent
    
    def _train_and_evaluate(
        self, 
        agent: SACAgent, 
        env, 
        trial: optuna.Trial,
        symbol: str
    ) -> Optional[float]:
        """
        ì—ì´ì „íŠ¸ í•™ìŠµ ë° í‰ê°€
        
        Returns:
            í‰ê°€ ìŠ¤ì½”ì–´ (None if failed)
        """
        portfolio_values = []
        returns = []
        episode_rewards = []
        
        try:
            for episode in range(self.n_episodes_per_trial):
                state = env.reset()
                episode_reward = 0
                episode_returns = []
                
                for step in range(MAX_STEPS_PER_EPISODE):
                    # í–‰ë™ ì„ íƒ
                    action = agent.select_action(state, evaluate=False)
                    
                    # í™˜ê²½ì—ì„œ ìŠ¤í… ì‹¤í–‰
                    next_state, reward, done, info = env.step(action)
                    
                    # ê²½í—˜ ì €ì¥
                    agent.add_experience(state, action, reward, next_state, done)
                    
                    # ëª¨ë¸ ì—…ë°ì´íŠ¸
                    if len(agent.replay_buffer) > agent.batch_size:
                        agent.update_parameters(agent.batch_size)
                    
                    episode_reward += reward
                    episode_returns.append(info['portfolio_value'])
                    
                    state = next_state
                    
                    if done:
                        break
                
                episode_rewards.append(episode_reward)
                portfolio_values.extend(episode_returns)
                
                # ì¤‘ê°„ ì„±ëŠ¥ ì²´í¬ (Pruning)
                if self.use_pruning and episode > 20 and episode % 10 == 0:
                    intermediate_score = self._calculate_score(episode_rewards, portfolio_values)
                    trial.report(intermediate_score, episode)
                    
                    if trial.should_prune():
                        raise optuna.TrialPruned(f"ì¤‘ê°„ ì„±ëŠ¥ ë¶€ì¡±ìœ¼ë¡œ ì¡°ê¸° ì¢…ë£Œ (episode {episode})")
            
            # ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚°
            final_score = self._calculate_score(episode_rewards, portfolio_values)
            return final_score
            
        except optuna.TrialPruned:
            raise
        except Exception as e:
            LOGGER.warning(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ({symbol}): {e}")
            return None
    
    def _calculate_score(self, episode_rewards: List[float], portfolio_values: List[float]) -> float:
        """ì„±ëŠ¥ ìŠ¤ì½”ì–´ ê³„ì‚°"""
        if not episode_rewards or not portfolio_values:
            return -np.inf
        
        try:
            if self.optimization_metric == 'total_return':
                initial_value = INITIAL_BALANCE
                final_value = portfolio_values[-1] if portfolio_values else initial_value
                return (final_value - initial_value) / initial_value
                
            elif self.optimization_metric == 'sharpe_ratio':
                returns = np.diff(portfolio_values) / portfolio_values[:-1] if len(portfolio_values) > 1 else [0]
                if len(returns) < 2 or np.std(returns) == 0:
                    return -np.inf
                return np.mean(returns) / np.std(returns) * np.sqrt(252)  # ì—°ê°„í™”
                
            elif self.optimization_metric == 'final_portfolio_value':
                return portfolio_values[-1] if portfolio_values else 0
                
            else:  # ê¸°ë³¸ê°’: í‰ê·  ì—í”¼ì†Œë“œ ë³´ìƒ
                return np.mean(episode_rewards)
                
        except Exception as e:
            LOGGER.warning(f"ìŠ¤ì½”ì–´ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return -np.inf
    
    def _save_best_params(self, params: Dict[str, Any], score: float, trial_number: int):
        """ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„° ì €ì¥"""
        best_params_file = self.results_dir / "best_hyperparameters.json"
        
        save_data = {
            'trial_number': trial_number,
            'score': float(score),
            'optimization_metric': self.optimization_metric,
            'model_type': self.model_type,
            'symbols': self.symbols,
            'hyperparameters': params,
            'timestamp': datetime.now().isoformat(),
            'n_episodes_per_trial': self.n_episodes_per_trial
        }
        
        with open(best_params_file, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        LOGGER.info(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„° ì €ì¥ë¨: {best_params_file}")
    
    def optimize(self) -> Dict[str, Any]:
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰
        
        Returns:
            ìµœì í™” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if self.data_results is None:
            self.prepare_data()
        
        LOGGER.info(f"ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
        LOGGER.info(f"   ëª¨ë¸: {self.model_type.upper()}")
        LOGGER.info(f"   ëª©í‘œ: {self.optimization_metric}")
        
        # Optuna ìŠ¤í„°ë”” ìƒì„±
        sampler = TPESampler(seed=self.random_seed)
        
        if self.use_pruning:
            pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=20)
        else:
            pruner = optuna.pruners.NopPruner()
        
        study = optuna.create_study(
            direction='maximize',
            sampler=sampler,
            pruner=pruner,
            study_name=f"sac_{self.model_type}_optimization"
        )
        
        # ìµœì í™” ì‹¤í–‰
        start_time = time.time()
        
        study.optimize(
            self.objective,
            n_trials=self.n_trials,
            timeout=None,
            show_progress_bar=True
        )
        
        optimization_time = time.time() - start_time
        
        # ê²°ê³¼ ì •ë¦¬ (ì™„ë£Œëœ trialì´ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬)
        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        
        if not completed_trials:
            LOGGER.error("âŒ ì™„ë£Œëœ trialì´ ì—†ìŠµë‹ˆë‹¤!")
            LOGGER.error(f"   ì´ ì‹œë„: {len(study.trials)}")
            LOGGER.error(f"   ì‹¤íŒ¨: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}")
            LOGGER.error(f"   ê°€ì§€ì¹˜ê¸°: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
            
            # ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            results = {
                'best_score': float('-inf'),
                'best_params': {},
                'model_type': self.model_type,
                'optimization_metric': self.optimization_metric,
                'symbols': self.symbols,
                'n_trials': len(study.trials),
                'optimization_time_hours': optimization_time / 3600,
                'study': study,
                'error': 'No completed trials'
            }
            return results
        
        best_trial = study.best_trial
        best_params = best_trial.params
        best_score = best_trial.value
        
        LOGGER.info(f"âœ… ìµœì í™” ì™„ë£Œ!")
        LOGGER.info(f"   ì†Œìš” ì‹œê°„: {optimization_time/3600:.2f} ì‹œê°„")
        LOGGER.info(f"   ìµœê³  ìŠ¤ì½”ì–´: {best_score:.4f}")
        LOGGER.info(f"   ì™„ë£Œëœ ì‹œë„: {len(study.trials)}")
        LOGGER.info(f"   ê°€ì§€ì¹˜ê¸°ëœ ì‹œë„: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        results = {
            'best_score': best_score,
            'best_params': best_params,
            'model_type': self.model_type,
            'optimization_metric': self.optimization_metric,
            'symbols': self.symbols,
            'n_trials': len(study.trials),
            'optimization_time_hours': optimization_time / 3600,
            'study': study
        }
        
        self._save_optimization_results(results, study)
        
        return results
    
    def _save_optimization_results(self, results: Dict[str, Any], study: optuna.Study):
        """ìµœì í™” ê²°ê³¼ ì €ì¥"""
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        results_file = self.results_dir / "optimization_results.json"
        save_data = {k: v for k, v in results.items() if k != 'study'}  # study ê°ì²´ ì œì™¸
        
        with open(results_file, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        # Optuna ìŠ¤í„°ë”” ì €ì¥
        study_file = self.results_dir / "optuna_study.pkl"
        optuna.pickle_storage.dump_study(study, study_file)
        
        # ì‹œê°í™” ìƒì„±
        self._create_optimization_plots(study)
        
        LOGGER.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.results_dir}")
    
    def _create_optimization_plots(self, study: optuna.Study):
        """ìµœì í™” ê²°ê³¼ ì‹œê°í™”"""
        try:
            import matplotlib.pyplot as plt
            
            # 1. ìµœì í™” íˆìŠ¤í† ë¦¬
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            
            # Trial ê°’ íˆìŠ¤í† ë¦¬
            trial_values = [t.value for t in study.trials if t.value is not None]
            trial_numbers = [t.number for t in study.trials if t.value is not None]
            
            axes[0, 0].plot(trial_numbers, trial_values, 'b-', alpha=0.6)
            axes[0, 0].axhline(y=study.best_value, color='r', linestyle='--', label=f'Best: {study.best_value:.4f}')
            axes[0, 0].set_xlabel('Trial')
            axes[0, 0].set_ylabel('Score')
            axes[0, 0].set_title('Optimization History')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ (ìƒìœ„ 5ê°œ)
            if len(study.trials) >= 10:
                try:
                    importance = optuna.importance.get_param_importances(study)
                    top_params = list(importance.items())[:5]
                    
                    if top_params:
                        params, values = zip(*top_params)
                        axes[0, 1].barh(params, values)
                        axes[0, 1].set_xlabel('Importance')
                        axes[0, 1].set_title('Parameter Importance (Top 5)')
                except:
                    axes[0, 1].text(0.5, 0.5, 'Parameter importance\ncalculation failed', 
                                   ha='center', va='center', transform=axes[0, 1].transAxes)
            else:
                axes[0, 1].text(0.5, 0.5, 'Not enough trials\nfor importance analysis', 
                               ha='center', va='center', transform=axes[0, 1].transAxes)
            
            # í•™ìŠµë¥  ë¶„í¬ (actor_lr ì˜ˆì‹œ)
            lr_values = [t.params.get('actor_lr') for t in study.trials if t.params.get('actor_lr')]
            if lr_values:
                axes[1, 0].hist(lr_values, bins=20, alpha=0.7, edgecolor='black')
                axes[1, 0].axvline(x=study.best_params.get('actor_lr', 0), color='r', linestyle='--', 
                                  label=f"Best: {study.best_params.get('actor_lr', 0):.2e}")
                axes[1, 0].set_xlabel('Actor Learning Rate')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].set_title('Actor LR Distribution')
                axes[1, 0].legend()
                axes[1, 0].set_xscale('log')
            
            # Hidden dimension ë¶„í¬
            hidden_dims = [t.params.get('hidden_dim') for t in study.trials if t.params.get('hidden_dim')]
            if hidden_dims:
                unique_dims, counts = np.unique(hidden_dims, return_counts=True)
                bars = axes[1, 1].bar(unique_dims.astype(str), counts, alpha=0.7, edgecolor='black')
                
                # ìµœê³  ì„±ëŠ¥ í•˜ì´ë“  ë””ë©˜ì…˜ ê°•ì¡°
                best_hidden = study.best_params.get('hidden_dim')
                if best_hidden in unique_dims:
                    best_idx = np.where(unique_dims == best_hidden)[0][0]
                    bars[best_idx].set_color('red')
                    bars[best_idx].set_alpha(1.0)
                
                axes[1, 1].set_xlabel('Hidden Dimension')
                axes[1, 1].set_ylabel('Frequency')
                axes[1, 1].set_title('Hidden Dimension Distribution')
                axes[1, 1].set_xticks(range(len(unique_dims)))
                axes[1, 1].set_xticklabels(unique_dims.astype(str))
            
            plt.tight_layout()
            plt.savefig(self.results_dir / "optimization_plots.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            LOGGER.info("ğŸ“Š ìµœì í™” ì‹œê°í™” ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            LOGGER.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
    
    def load_best_hyperparameters(self, file_path: str = None) -> Dict[str, Any]:
        """ì €ì¥ëœ ìµœê³  ì„±ëŠ¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ"""
        if file_path is None:
            file_path = self.results_dir / "best_hyperparameters.json"
        
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            LOGGER.info(f"âœ… ìµœê³  ì„±ëŠ¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œë¨: {file_path}")
            LOGGER.info(f"   ìŠ¤ì½”ì–´: {data['score']:.4f}")
            LOGGER.info(f"   Trial: {data['trial_number']}")
            
            return data
            
        except FileNotFoundError:
            LOGGER.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return {}
        except Exception as e:
            LOGGER.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}


def run_hyperparameter_optimization(
    symbols: List[str] = None,
    model_type: str = 'mlp',
    n_trials: int = 50,
    n_episodes_per_trial: int = 100,
    optimization_metric: str = 'sharpe_ratio'
) -> Dict[str, Any]:
    """
    í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        symbols: ì‚¬ìš©í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        model_type: ëª¨ë¸ íƒ€ì…
        n_trials: ì‹œë„ íšŸìˆ˜
        n_episodes_per_trial: ì—í”¼ì†Œë“œ ìˆ˜
        optimization_metric: ìµœì í™” ì§€í‘œ
        
    Returns:
        ìµœì í™” ê²°ê³¼
    """
    
    LOGGER.info("ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
    
    # ìµœì í™” ê°ì²´ ìƒì„±
    optimizer = HyperparameterOptimizer(
        symbols=symbols or TARGET_SYMBOLS[:2],
        model_type=model_type,
        n_trials=n_trials,
        n_episodes_per_trial=n_episodes_per_trial,
        optimization_metric=optimization_metric,
        use_pruning=True,
        random_seed=42
    )
    
    # ìµœì í™” ì‹¤í–‰
    results = optimizer.optimize()
    
    # ê²°ê³¼ ì¶œë ¥
    LOGGER.info("=" * 60)
    LOGGER.info("ğŸ† í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼")
    LOGGER.info("=" * 60)
    LOGGER.info(f"ëª¨ë¸ íƒ€ì…: {model_type.upper()}")
    LOGGER.info(f"ìµœê³  ìŠ¤ì½”ì–´: {results['best_score']:.4f}")
    LOGGER.info(f"ìµœì  íŒŒë¼ë¯¸í„°:")
    
    for param, value in results['best_params'].items():
        if isinstance(value, float):
            LOGGER.info(f"  {param}: {value:.6f}")
        else:
            LOGGER.info(f"  {param}: {value}")
    
    LOGGER.info("=" * 60)
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='SAC í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”')
    parser.add_argument('--model_type', choices=['mlp', 'cnn', 'lstm', 'mamba'], default='mlp',
                       help='ìµœì í™”í•  ëª¨ë¸ íƒ€ì…')
    parser.add_argument('--symbols', nargs='+', default=None,
                       help='ì‚¬ìš©í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸')
    parser.add_argument('--n_trials', type=int, default=50,
                       help='ìµœì í™” ì‹œë„ íšŸìˆ˜')
    parser.add_argument('--n_episodes', type=int, default=100,
                       help='ê° ì‹œë„ë‹¹ í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--metric', choices=['sharpe_ratio', 'total_return', 'final_portfolio_value'],
                       default='sharpe_ratio', help='ìµœì í™” ì§€í‘œ')
    
    args = parser.parse_args()
    
    # ìµœì í™” ì‹¤í–‰
    results = run_hyperparameter_optimization(
        symbols=args.symbols,
        model_type=args.model_type,
        n_trials=args.n_trials,
        n_episodes_per_trial=args.n_episodes,
        optimization_metric=args.metric
    )
    
    print(f"\nğŸ‰ ìµœì í™” ì™„ë£Œ! ê²°ê³¼ëŠ” {results.get('results_dir', 'hyperopt_results')} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.") 