#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ê· í˜•ì¡íŒ SAC ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ë§¤ìˆ˜ í¸í–¥ ë¬¸ì œ í•´ê²°)
"""
import os
import argparse
import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
from datetime import datetime
import sys
from pathlib import Path
import time
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.append(project_root)

from src.models.sac_agent import SACAgent
from src.environment.trading_env_balanced import create_balanced_environment_from_results
from src.data_collection.data_collector import DataCollector
from src.preprocessing.data_processor import DataProcessor
from src.config.ea_teb_config import (
    DEVICE,
    TARGET_SYMBOLS,
    LOGGER,
    WINDOW_SIZE,
    INITIAL_BALANCE,
    TRANSACTION_FEE_PERCENT,
    BATCH_SIZE,
    NUM_EPISODES,
)
from src.utils.utils import create_directory


def parse_args():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='ê· í˜•ì¡íŒ SAC ëª¨ë¸ í•™ìŠµ')

    # ë°ì´í„° ê´€ë ¨
    parser.add_argument('--symbols', nargs='+', default=None, help='í•™ìŠµí•  ì£¼ì‹ ì‹¬ë³¼ ëª©ë¡')
    parser.add_argument('--collect_data', action='store_true', help='ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì—¬ë¶€')

    # í™˜ê²½ ê´€ë ¨
    parser.add_argument('--window_size', type=int, default=WINDOW_SIZE, help='ê´€ì¸¡ ìœˆë„ìš° í¬ê¸°')
    parser.add_argument('--initial_balance', type=float, default=INITIAL_BALANCE, help='ì´ˆê¸° ìë³¸ê¸ˆ')
    parser.add_argument('--transaction_fee_percent', type=float, default=TRANSACTION_FEE_PERCENT, help='ê±°ë˜ ìˆ˜ìˆ˜ë£Œìœ¨')
    
    # ê· í˜•ì¡íŒ í™˜ê²½ ì „ìš© ì„¤ì •
    parser.add_argument('--balanced_initialization', action='store_true', default=True, 
                        help='ê· í˜•ì¡íŒ ì´ˆê¸°í™” (50% í˜„ê¸ˆ, 50% ì£¼ì‹)')
    parser.add_argument('--disable_balanced_init', action='store_true', 
                        help='ê· í˜•ì¡íŒ ì´ˆê¸°í™” ë¹„í™œì„±í™”')

    # í•™ìŠµ ê´€ë ¨
    parser.add_argument('--num_episodes', type=int, default=100, help='í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜ (ê· í˜•ì¡íŒ ê¸°ë³¸ê°’)')
    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--max_steps_per_episode', type=int, default=1000, help='ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í…')

    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument('--use_cnn', action='store_true', help='CNN ëª¨ë¸ ì‚¬ìš©')
    parser.add_argument('--use_lstm', action='store_true', help='LSTM ëª¨ë¸ ì‚¬ìš©')
    parser.add_argument('--use_mamba', action='store_true', help='Mamba ëª¨ë¸ ì‚¬ìš©')
    parser.add_argument('--use_tinytransformer', action='store_true', help='TinyTransformer ëª¨ë¸ ì‚¬ìš©')

    # í•™ìŠµë¥  ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê· í˜•ì¡íŒ í•™ìŠµì— ìµœì í™”)
    parser.add_argument('--actor_lr', type=float, default=3e-5, help='Actor í•™ìŠµë¥  (ê· í˜•ì¡íŒ ê¸°ë³¸ê°’)')
    parser.add_argument('--critic_lr', type=float, default=3e-4, help='Critic í•™ìŠµë¥ ')
    parser.add_argument('--alpha_lr', type=float, default=3e-5, help='Alpha í•™ìŠµë¥ ')

    # ê²°ê³¼ ì €ì¥
    parser.add_argument('--save_dir', type=str, default='models_balanced', help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--log_level', type=str, default='normal', 
                        choices=['minimal', 'normal', 'detailed'], help='ë¡œê·¸ ë ˆë²¨')

    return parser.parse_args()


def analyze_action_balance(episode_actions_history, num_recent=5):
    """í–‰ë™ ê· í˜• ë¶„ì„"""
    if len(episode_actions_history) < num_recent:
        return "ë¶„ì„ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    recent_episodes = episode_actions_history[-num_recent:]
    all_actions = []
    
    for actions in recent_episodes:
        all_actions.extend(actions)
    
    if not all_actions:
        return "í–‰ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    actions_array = np.array(all_actions)
    
    # í–‰ë™ ë¶„í¬ ë¶„ì„ (ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜ í›„)
    # action -> target_ratio ë³€í™˜: 1 / (1 + exp(-action * 2))
    target_ratios = 1 / (1 + np.exp(-actions_array * 2))
    
    # ë§¤ìˆ˜/ë§¤ë„ íŒë‹¨ (50% ê¸°ì¤€)
    buy_actions = np.sum(target_ratios > 0.6)  # 60% ì´ìƒ ì£¼ì‹ -> ë§¤ìˆ˜ ì„±í–¥
    sell_actions = np.sum(target_ratios < 0.4)  # 40% ë¯¸ë§Œ ì£¼ì‹ -> ë§¤ë„ ì„±í–¥
    hold_actions = np.sum((target_ratios >= 0.4) & (target_ratios <= 0.6))  # ì¤‘ë¦½
    total_actions = len(actions_array)
    
    buy_ratio = buy_actions / total_actions * 100
    sell_ratio = sell_actions / total_actions * 100
    hold_ratio = hold_actions / total_actions * 100
    
    # ê· í˜• ì ìˆ˜ ê³„ì‚°
    balance_score = 100 - abs(buy_ratio - sell_ratio)
    
    analysis = f"""
ğŸ¯ ìµœê·¼ {num_recent}ê°œ ì—í”¼ì†Œë“œ í–‰ë™ ê· í˜• ë¶„ì„:
   â””â”€ ë§¤ìˆ˜ ì„±í–¥: {buy_ratio:.1f}% | ë§¤ë„ ì„±í–¥: {sell_ratio:.1f}% | ì¤‘ë¦½: {hold_ratio:.1f}%
   â””â”€ í‰ê·  í–‰ë™ê°’: {np.mean(actions_array):+.3f}
   â””â”€ í‰ê·  ëª©í‘œ ë¹„ìœ¨: {np.mean(target_ratios):.3f}
   â””â”€ í–‰ë™ ë‹¤ì–‘ì„±: {np.std(actions_array):.3f}
   â””â”€ ê· í˜• ì ìˆ˜: {balance_score:.1f}/100
   â””â”€ ê· í˜• ìƒíƒœ: {'ğŸ¯ ê· í˜•ì¡í˜' if balance_score > 70 else 'âš ï¸ í¸í–¥ë¨' if balance_score > 40 else 'âŒ ì‹¬ê°í•œ í¸í–¥'}
    """
    
    return analysis


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print('=' * 80)
    LOGGER.info('ğŸ¯ ê· í˜•ì¡íŒ SAC ëª¨ë¸ í•™ìŠµ ì‹œì‘')

    # ì¸ì íŒŒì‹±
    args = parse_args()

    # ì‹¬ë³¼ ëª©ë¡ ì„¤ì •
    symbols = args.symbols if args.symbols else TARGET_SYMBOLS[:1]  # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì‹¬ë³¼ë§Œ
    symbol = symbols[0] if isinstance(symbols, list) else symbols

    LOGGER.info(f"ğŸ¯ ê· í˜•ì¡íŒ í•™ìŠµ ì„¤ì •:")
    LOGGER.info(f"   â””â”€ ì‹¬ë³¼: {symbol}")
    LOGGER.info(f"   â””â”€ ì—í”¼ì†Œë“œ ìˆ˜: {args.num_episodes}")
    LOGGER.info(f"   â””â”€ ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    LOGGER.info(f"   â””â”€ ê· í˜•ì¡íŒ ì´ˆê¸°í™”: {args.balanced_initialization and not args.disable_balanced_init}")
    LOGGER.info(f"   â””â”€ Actor LR: {args.actor_lr}")

    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = Path(args.save_dir) / f"balanced_{symbol}_{timestamp}"
    create_directory(save_dir)

    LOGGER.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {save_dir}")

    try:
        # ë°ì´í„° ìˆ˜ì§‘
        LOGGER.info("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        collector = DataCollector(symbols=[symbol])
        data = collector.load_all_data()
        
        if not data:
            LOGGER.info("ğŸ”„ ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            data = collector.load_and_save()

        # ë°ì´í„° ì „ì²˜ë¦¬
        LOGGER.info("âš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        processor = DataProcessor(window_size=args.window_size)
        results = processor.process_all_symbols(data)

        # ê· í˜•ì¡íŒ í™˜ê²½ ìƒì„±
        LOGGER.info(f"ğŸ—ï¸ ê· í˜•ì¡íŒ í•™ìŠµ í™˜ê²½ ìƒì„±: {symbol}")
        
        balanced_init = args.balanced_initialization and not args.disable_balanced_init
        
        env = create_balanced_environment_from_results(
            results=results,
            symbol=symbol,
            data_type='train',
            window_size=args.window_size,
            initial_balance=args.initial_balance,
            transaction_fee_percent=args.transaction_fee_percent,
            balanced_initialization=balanced_init,
            log_level=args.log_level
        )

        LOGGER.info(f"âœ… ê· í˜•ì¡íŒ í™˜ê²½ ìƒì„± ì™„ë£Œ (ê· í˜• ì´ˆê¸°í™”: {balanced_init})")

        # ì—ì´ì „íŠ¸ ìƒì„±
        LOGGER.info("ğŸ¤– ê· í˜•ì¡íŒ SAC ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...")
        
        obs = env.reset()
        input_shape = obs['market_data'].shape if isinstance(obs, dict) else None
        state_dim = None if input_shape else len(obs)

        agent = SACAgent(
            state_dim=state_dim,
            action_dim=1,
            input_shape=input_shape,
            use_cnn=args.use_cnn,
            use_lstm=args.use_lstm,
            use_mamba=args.use_mamba,
            use_tinytransformer=args.use_tinytransformer,
            actor_lr=args.actor_lr,
            critic_lr=args.critic_lr,
            alpha_lr=args.alpha_lr,
            alpha_init=0.1,  # ë‚®ì€ ì´ˆê¸° ì—”íŠ¸ë¡œí”¼
            gamma=0.99,
            tau=0.005,
            device=DEVICE
        )

        # ê· í˜•ì¡íŒ í•™ìŠµ ì‹¤í–‰
        LOGGER.info("ğŸš€ ê· í˜•ì¡íŒ í•™ìŠµ ì‹œì‘!")
        
        episode_rewards = []
        episode_actions_history = []
        
        for episode in range(args.num_episodes):
            state = env.reset()
            done = False
            episode_reward = 0
            episode_actions = []
            step = 0

            while not done and step < args.max_steps_per_episode:
                action = agent.select_action(state, evaluate=False)
                episode_actions.append(action)

                next_state, reward, done, info = env.step(action)
                agent.add_experience(state, action, reward, next_state, done)

                if len(agent.replay_buffer) > args.batch_size:
                    agent.update_parameters(args.batch_size)

                state = next_state
                episode_reward += reward if isinstance(reward, (int, float)) else reward
                step += 1

            episode_rewards.append(episode_reward)
            episode_actions_history.append(episode_actions)

            # ì§„í–‰ ìƒí™© ë¡œê¹…
            if episode % 10 == 0:
                avg_reward = np.mean(episode_rewards[-10:])
                LOGGER.info(f"ğŸ¯ ì—í”¼ì†Œë“œ {episode+1}/{args.num_episodes} - í‰ê·  ë³´ìƒ: {avg_reward:.4f}")
                
                if episode >= 20:
                    balance_analysis = analyze_action_balance(episode_actions_history, num_recent=10)
                    LOGGER.info(balance_analysis)

        # ëª¨ë¸ ì €ì¥
        model_type = 'TinyTransformer' if args.use_tinytransformer else 'LSTM' if args.use_lstm else 'Mamba' if args.use_mamba else 'CNN' if args.use_cnn else 'MLP'
        
        saved_path = agent.save_model(
            save_dir=save_dir,
            prefix=f"balanced_{model_type}",
            symbol=symbol
        )

        # ìµœì¢… ê· í˜• ë¶„ì„
        if episode_actions_history:
            final_analysis = analyze_action_balance(episode_actions_history, num_recent=min(20, len(episode_actions_history)))
            LOGGER.info("ğŸ ìµœì¢… ê· í˜•ì¡íŒ í•™ìŠµ ê²°ê³¼:")
            LOGGER.info(final_analysis)

        LOGGER.info("=" * 80)
        LOGGER.info(f"ğŸ‰ ê· í˜•ì¡íŒ í•™ìŠµ ì™„ë£Œ! - {symbol}")
        LOGGER.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {saved_path}")
        LOGGER.info(f"ğŸ¤– ëª¨ë¸ íƒ€ì…: {model_type}")
        LOGGER.info(f"ğŸ¯ ê· í˜•ì¡íŒ í•™ìŠµ: í™œì„±í™”")
        LOGGER.info("=" * 80)

        return saved_path

    except Exception as e:
        LOGGER.error(f"âŒ ê· í˜•ì¡íŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        LOGGER.error(traceback.format_exc())


if __name__ == "__main__":
    main() 